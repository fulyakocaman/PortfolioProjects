In this project I worked with some toy data sets and used Seaborn, pandas, scikit-learn, NumPy and pyplot to analyze some toy datasets and compare the decision boundaries defined by 

Experiments
Run the following experiments in a Jupyter notebook, performing actions in code cells and reporting results in Markdown cells.
1.Use read_csv() to load and examine each dataset.
2.Use logistic regression to fit() and score() a binary classifier for dataset 1. How accurate are the model’s predictions?
3.Repeat experiment (2) for dataset 2. How well does it score?
4.Create separate scatterplots for datasets 1 and 2, plotting points from class 0 with a different color and marker from points 
in class 1. What accounts for the discrepancies between experiments (2) and (3)?
5.Fit and score Gaussian Naive Bayes classifiers for datasets 1 and 2. How well do these classifiers score compared to logistic 
regression?
6.Repeat experiment (5) with K-Nearest Neighbor classifiers.
7.Use the code from KV Subbaiah Setty’s tutorial How To Plot A Decision Boundary For Machine Learning Algorithms in Python as a
 guide, plot the decision boundaries for each classifier and dataset. What differences do you observe?
8.Now repeat experiments (2), (5), (6), and (7) with dataset 3.  
